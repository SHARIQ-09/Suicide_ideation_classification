{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qqq transformers datasets wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\python\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 6\n",
    "LEARNING_RATE = 1e-5\n",
    "SEED = 4222\n",
    "\n",
    "MODEL_SAVE_PATH = \"Models/bert\"\n",
    "MODEL_CHECKPOINT_PATH = \"Models/bert_checkpoint\"\n",
    "MODEL_LOGGING_PATH = \"Models/bert_checkpoint/logs\"\n",
    "\n",
    "WANDB_ENTITY = \"irshad-shariq-liverpool-john-moores-university\"\n",
    "WANDB_PROJECT = \"suicide-detection\"\n",
    "WANDB_RUN = \"bert\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ex Wife Threatening SuicideRecently I left my ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Am I weird I don't get affected by compliments...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finally 2020 is almost over... So I can never ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It ends tonight.I can‚Äôt do it anymore. \\nI quit.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Ex Wife Threatening SuicideRecently I left my ...      1\n",
       "1  Am I weird I don't get affected by compliments...      0\n",
       "2  Finally 2020 is almost over... So I can never ...      0\n",
       "3          i need helpjust help me im crying so hard      1\n",
       "4   It ends tonight.I can‚Äôt do it anymore. \\nI quit.      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('suicide_detection_final_cleaned.csv', header=0, names=['text', 'label', 'cleaned_text'])\n",
    "df['label'] = df['label'].map({'suicide': 1, 'non-suicide': 0})\n",
    "df.drop(columns=['cleaned_text'], inplace = True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train, validation and test sets\n",
    "train, temp = train_test_split(df,\n",
    "                               random_state=SEED,\n",
    "                               test_size=0.2,\n",
    "                               stratify=df['label'])\n",
    "\n",
    "val, test = train_test_split(temp,\n",
    "                             random_state=SEED,\n",
    "                             test_size=0.5,\n",
    "                             stratify=temp['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dataset_conversion(train, test, val):\n",
    "  \"\"\"Converts pandas dataframe to Dataset.\"\"\"\n",
    "\n",
    "  train.reset_index(drop=True, inplace=True)\n",
    "  test.reset_index(drop=True, inplace=True)\n",
    "  val.reset_index(drop=True, inplace=True)\n",
    "\n",
    "  train_dataset = Dataset.from_pandas(train)\n",
    "  test_dataset = Dataset.from_pandas(test)\n",
    "  val_dataset = Dataset.from_pandas(val)\n",
    "\n",
    "  return DatasetDict({\"train\": train_dataset,\n",
    "                      \"test\": test_dataset,\n",
    "                      \"val\": val_dataset})\n",
    "\n",
    "raw_datasets = dataset_conversion(train, test, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8fd1f1e3184995b3b27a810f4a81d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/140523 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf0a0bbcc87427493ccfff5e9edfe23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17566 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e83a34199e45ce8bab51ee2320bb53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17565 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(dataset):\n",
    "    return tokenizer(dataset[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenise datasets\n",
    "SAMPLE_SIZE = 20\n",
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=SEED).select(range(SAMPLE_SIZE))\n",
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=SEED).select(range(SAMPLE_SIZE))\n",
    "small_val_dataset = tokenized_datasets[\"val\"].shuffle(seed=SEED).select(range(SAMPLE_SIZE))\n",
    "\n",
    "full_train_dataset = tokenized_datasets[\"train\"]\n",
    "full_test_dataset = tokenized_datasets[\"test\"]\n",
    "full_val_dataset = tokenized_datasets[\"val\"]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Import BERT-base pretrained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mirshad-shariq\u001b[0m (\u001b[33mirshad-shariq-liverpool-john-moores-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['WANDB_BASE_URL'] = 'https://api.wandb.ai'\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'bert.ipynb'\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Thesis_Code\\wandb\\run-20240729_184035-5jbw2h1y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/irshad-shariq-liverpool-john-moores-university/suicide-detection/runs/5jbw2h1y' target=\"_blank\">bert</a></strong> to <a href='https://wandb.ai/irshad-shariq-liverpool-john-moores-university/suicide-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/irshad-shariq-liverpool-john-moores-university/suicide-detection' target=\"_blank\">https://wandb.ai/irshad-shariq-liverpool-john-moores-university/suicide-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/irshad-shariq-liverpool-john-moores-university/suicide-detection/runs/5jbw2h1y' target=\"_blank\">https://wandb.ai/irshad-shariq-liverpool-john-moores-university/suicide-detection/runs/5jbw2h1y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/irshad-shariq-liverpool-john-moores-university/suicide-detection/runs/5jbw2h1y?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x23ebc506810>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise wandb\n",
    "wandb.init(project=WANDB_PROJECT, entity=WANDB_ENTITY, name=WANDB_RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom metrics for computation\n",
    "def compute_metrics(eval_pred):\n",
    "    metric_acc = load_metric(\"accuracy\",trust_remote_code=True )\n",
    "    metric_rec = load_metric(\"recall\",trust_remote_code=True)\n",
    "    metric_pre = load_metric(\"precision\",trust_remote_code=True)\n",
    "    metric_f1 = load_metric(\"f1\",trust_remote_code=True)\n",
    "    \n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    accuracy = metric_acc.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    recall = metric_rec.compute(predictions=predictions, references=labels)[\"recall\"]\n",
    "    precision = metric_pre.compute(predictions=predictions, references=labels)[\"precision\"]\n",
    "    f1 = metric_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"recall\": recall, \"precision\": precision, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define model and training parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_CHECKPOINT_PATH,\n",
    "    overwrite_output_dir = True,\n",
    "    report_to = 'wandb',\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    seed=SEED,\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    run_name=WANDB_RUN,\n",
    "    logging_dir=MODEL_LOGGING_PATH,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1500\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=full_train_dataset,\n",
    "    eval_dataset=full_val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03b7bc66c094e8da605d7204424ba46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2928 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shari\\AppData\\Local\\Temp\\ipykernel_25840\\1038578031.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric_acc = load_metric(\"accuracy\",trust_remote_code=True )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.6368388533592224,\n",
       " 'test_accuracy': 0.655641580325629,\n",
       " 'test_recall': 0.22600936220011703,\n",
       " 'test_precision': 0.6708640903169778,\n",
       " 'test_f1': 0.3381113907429697,\n",
       " 'test_runtime': 407.1263,\n",
       " 'test_samples_per_second': 43.146,\n",
       " 'test_steps_per_second': 7.192}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Predict before fine-tuning\n",
    "trainer.predict(full_test_dataset).metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuned - BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0835d655f0db47ce91b49b51885efae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2599, 'grad_norm': 133.1292724609375, 'learning_rate': 9.7865163741941e-06, 'epoch': 0.02}\n",
      "{'loss': 0.2104, 'grad_norm': 18.876489639282227, 'learning_rate': 9.573032748388199e-06, 'epoch': 0.04}\n",
      "{'loss': 0.1786, 'grad_norm': 0.33040517568588257, 'learning_rate': 9.3595491225823e-06, 'epoch': 0.06}\n",
      "{'loss': 0.1663, 'grad_norm': 2.0942471027374268, 'learning_rate': 9.146065496776399e-06, 'epoch': 0.09}\n",
      "{'loss': 0.1803, 'grad_norm': 0.2263522744178772, 'learning_rate': 8.932581870970498e-06, 'epoch': 0.11}\n",
      "{'loss': 0.1412, 'grad_norm': 0.09051486104726791, 'learning_rate': 8.719098245164597e-06, 'epoch': 0.13}\n",
      "{'loss': 0.16, 'grad_norm': 1.1409860849380493, 'learning_rate': 8.505614619358696e-06, 'epoch': 0.15}\n",
      "{'loss': 0.1436, 'grad_norm': 40.575416564941406, 'learning_rate': 8.292130993552795e-06, 'epoch': 0.17}\n",
      "{'loss': 0.1413, 'grad_norm': 12.876981735229492, 'learning_rate': 8.078647367746895e-06, 'epoch': 0.19}\n",
      "{'loss': 0.1676, 'grad_norm': 0.053067564964294434, 'learning_rate': 7.865163741940994e-06, 'epoch': 0.21}\n",
      "{'loss': 0.1424, 'grad_norm': 0.17142359912395477, 'learning_rate': 7.651680116135094e-06, 'epoch': 0.23}\n",
      "{'loss': 0.1392, 'grad_norm': 0.030124468728899956, 'learning_rate': 7.4381964903291925e-06, 'epoch': 0.26}\n",
      "{'loss': 0.1071, 'grad_norm': 0.013288864865899086, 'learning_rate': 7.224712864523291e-06, 'epoch': 0.28}\n",
      "{'loss': 0.1113, 'grad_norm': 0.030145980417728424, 'learning_rate': 7.011229238717391e-06, 'epoch': 0.3}\n",
      "{'loss': 0.1126, 'grad_norm': 8.95434856414795, 'learning_rate': 6.7977456129114905e-06, 'epoch': 0.32}\n",
      "{'loss': 0.1238, 'grad_norm': 0.059921760112047195, 'learning_rate': 6.584261987105589e-06, 'epoch': 0.34}\n",
      "{'loss': 0.1278, 'grad_norm': 0.055918723344802856, 'learning_rate': 6.3707783612996885e-06, 'epoch': 0.36}\n",
      "{'loss': 0.1256, 'grad_norm': 73.30326080322266, 'learning_rate': 6.157294735493788e-06, 'epoch': 0.38}\n",
      "{'loss': 0.1376, 'grad_norm': 0.010835068300366402, 'learning_rate': 5.943811109687887e-06, 'epoch': 0.41}\n",
      "{'loss': 0.1152, 'grad_norm': 8.76348876953125, 'learning_rate': 5.7303274838819865e-06, 'epoch': 0.43}\n",
      "{'loss': 0.1104, 'grad_norm': 0.02916429191827774, 'learning_rate': 5.516843858076086e-06, 'epoch': 0.45}\n",
      "{'loss': 0.1299, 'grad_norm': 0.006499331444501877, 'learning_rate': 5.3033602322701845e-06, 'epoch': 0.47}\n",
      "{'loss': 0.1077, 'grad_norm': 0.0816364586353302, 'learning_rate': 5.089876606464284e-06, 'epoch': 0.49}\n",
      "{'loss': 0.1121, 'grad_norm': 0.01721714809536934, 'learning_rate': 4.8763929806583834e-06, 'epoch': 0.51}\n",
      "{'loss': 0.1018, 'grad_norm': 0.09837473928928375, 'learning_rate': 4.662909354852483e-06, 'epoch': 0.53}\n",
      "{'loss': 0.1227, 'grad_norm': 0.018878428265452385, 'learning_rate': 4.449425729046582e-06, 'epoch': 0.56}\n",
      "{'loss': 0.1264, 'grad_norm': 0.016108861193060875, 'learning_rate': 4.235942103240681e-06, 'epoch': 0.58}\n",
      "{'loss': 0.115, 'grad_norm': 0.14020289480686188, 'learning_rate': 4.022458477434781e-06, 'epoch': 0.6}\n",
      "{'loss': 0.1239, 'grad_norm': 0.010285238735377789, 'learning_rate': 3.8089748516288807e-06, 'epoch': 0.62}\n",
      "{'loss': 0.1371, 'grad_norm': 34.70420455932617, 'learning_rate': 3.5954912258229797e-06, 'epoch': 0.64}\n",
      "{'loss': 0.114, 'grad_norm': 0.06295344978570938, 'learning_rate': 3.3820076000170787e-06, 'epoch': 0.66}\n",
      "{'loss': 0.1059, 'grad_norm': 0.2281215637922287, 'learning_rate': 3.1685239742111786e-06, 'epoch': 0.68}\n",
      "{'loss': 0.1098, 'grad_norm': 0.002556871622800827, 'learning_rate': 2.9550403484052776e-06, 'epoch': 0.7}\n",
      "{'loss': 0.1001, 'grad_norm': 0.06471530348062515, 'learning_rate': 2.7415567225993767e-06, 'epoch': 0.73}\n",
      "{'loss': 0.104, 'grad_norm': 0.7753867506980896, 'learning_rate': 2.5280730967934765e-06, 'epoch': 0.75}\n",
      "{'loss': 0.0932, 'grad_norm': 0.0025134803727269173, 'learning_rate': 2.3145894709875756e-06, 'epoch': 0.77}\n",
      "{'loss': 0.1101, 'grad_norm': 0.021331630647182465, 'learning_rate': 2.101105845181675e-06, 'epoch': 0.79}\n",
      "{'loss': 0.0904, 'grad_norm': 0.0021399292163550854, 'learning_rate': 1.887622219375774e-06, 'epoch': 0.81}\n",
      "{'loss': 0.0921, 'grad_norm': 29.10820960998535, 'learning_rate': 1.6741385935698735e-06, 'epoch': 0.83}\n",
      "{'loss': 0.1163, 'grad_norm': 0.009202135726809502, 'learning_rate': 1.4606549677639725e-06, 'epoch': 0.85}\n",
      "{'loss': 0.1029, 'grad_norm': 0.25391584634780884, 'learning_rate': 1.247171341958072e-06, 'epoch': 0.88}\n",
      "{'loss': 0.1037, 'grad_norm': 0.11531169712543488, 'learning_rate': 1.0336877161521712e-06, 'epoch': 0.9}\n",
      "{'loss': 0.0943, 'grad_norm': 0.058918703347444534, 'learning_rate': 8.202040903462705e-07, 'epoch': 0.92}\n",
      "{'loss': 0.0884, 'grad_norm': 0.12316370755434036, 'learning_rate': 6.067204645403698e-07, 'epoch': 0.94}\n",
      "{'loss': 0.1046, 'grad_norm': 0.25131234526634216, 'learning_rate': 3.9323683873446906e-07, 'epoch': 0.96}\n",
      "{'loss': 0.1061, 'grad_norm': 15.60807991027832, 'learning_rate': 1.797532129285684e-07, 'epoch': 0.98}\n",
      "{'train_runtime': 18379.1875, 'train_samples_per_second': 7.646, 'train_steps_per_second': 1.274, 'train_loss': 0.12578321235154757, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857b028f7aa147ab9ba50b79cd46165b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1299, 'grad_norm': 0.006499331444501877, 'learning_rate': 5.3033602322701845e-06, 'epoch': 0.47}\n",
      "{'loss': 0.1077, 'grad_norm': 0.0816364586353302, 'learning_rate': 5.089876606464284e-06, 'epoch': 0.49}\n",
      "{'loss': 0.1121, 'grad_norm': 0.01721714809536934, 'learning_rate': 4.8763929806583834e-06, 'epoch': 0.51}\n",
      "{'loss': 0.1018, 'grad_norm': 0.09837473928928375, 'learning_rate': 4.662909354852483e-06, 'epoch': 0.53}\n",
      "{'loss': 0.1227, 'grad_norm': 0.01886860653758049, 'learning_rate': 4.449425729046582e-06, 'epoch': 0.56}\n",
      "{'loss': 0.1263, 'grad_norm': 0.01636587083339691, 'learning_rate': 4.235942103240681e-06, 'epoch': 0.58}\n",
      "{'loss': 0.1149, 'grad_norm': 0.1511491984128952, 'learning_rate': 4.022458477434781e-06, 'epoch': 0.6}\n",
      "{'loss': 0.1244, 'grad_norm': 0.01034220214933157, 'learning_rate': 3.8089748516288807e-06, 'epoch': 0.62}\n",
      "{'loss': 0.1366, 'grad_norm': 34.354061126708984, 'learning_rate': 3.5954912258229797e-06, 'epoch': 0.64}\n",
      "{'loss': 0.113, 'grad_norm': 0.06431149691343307, 'learning_rate': 3.3820076000170787e-06, 'epoch': 0.66}\n",
      "{'loss': 0.1061, 'grad_norm': 0.2225867658853531, 'learning_rate': 3.1685239742111786e-06, 'epoch': 0.68}\n",
      "{'loss': 0.1081, 'grad_norm': 0.002779076574370265, 'learning_rate': 2.9550403484052776e-06, 'epoch': 0.7}\n",
      "{'loss': 0.1, 'grad_norm': 0.06606481224298477, 'learning_rate': 2.7415567225993767e-06, 'epoch': 0.73}\n",
      "{'loss': 0.1039, 'grad_norm': 0.4636237323284149, 'learning_rate': 2.5280730967934765e-06, 'epoch': 0.75}\n",
      "{'loss': 0.0929, 'grad_norm': 0.0025440147146582603, 'learning_rate': 2.3145894709875756e-06, 'epoch': 0.77}\n",
      "{'loss': 0.1103, 'grad_norm': 0.02210531011223793, 'learning_rate': 2.101105845181675e-06, 'epoch': 0.79}\n",
      "{'loss': 0.0902, 'grad_norm': 0.0022486180532723665, 'learning_rate': 1.887622219375774e-06, 'epoch': 0.81}\n",
      "{'loss': 0.0918, 'grad_norm': 34.51374435424805, 'learning_rate': 1.6741385935698735e-06, 'epoch': 0.83}\n",
      "{'loss': 0.1163, 'grad_norm': 0.009646883234381676, 'learning_rate': 1.4606549677639725e-06, 'epoch': 0.85}\n",
      "{'loss': 0.103, 'grad_norm': 0.25881192088127136, 'learning_rate': 1.247171341958072e-06, 'epoch': 0.88}\n",
      "{'loss': 0.1038, 'grad_norm': 0.11774224042892456, 'learning_rate': 1.0336877161521712e-06, 'epoch': 0.9}\n",
      "{'loss': 0.0943, 'grad_norm': 0.06458306312561035, 'learning_rate': 8.202040903462705e-07, 'epoch': 0.92}\n",
      "{'loss': 0.0881, 'grad_norm': 0.1414930820465088, 'learning_rate': 6.067204645403698e-07, 'epoch': 0.94}\n",
      "{'loss': 0.1056, 'grad_norm': 0.2654852569103241, 'learning_rate': 3.9323683873446906e-07, 'epoch': 0.96}\n",
      "{'loss': 0.1051, 'grad_norm': 15.901348114013672, 'learning_rate': 1.797532129285684e-07, 'epoch': 0.98}\n",
      "{'train_runtime': 4951.4707, 'train_samples_per_second': 28.38, 'train_steps_per_second': 4.73, 'train_loss': 0.05946184355974106, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=23421, training_loss=0.05946184355974106, metrics={'train_runtime': 4951.4707, 'train_samples_per_second': 28.38, 'train_steps_per_second': 4.73, 'total_flos': 3.697315483235328e+16, 'train_loss': 0.05946184355974106, 'epoch': 1.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# To observe training progress live\n",
    "#%%wandb \n",
    "\n",
    "# Fine-tune model\n",
    "trainer.train()\n",
    "\n",
    "# Resume fine-tuning from checkpoint\n",
    "trainer.train(MODEL_CHECKPOINT_PATH + \"/\" + \"checkpoint-10500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save fine-tuned model\n",
    "trainer.save_model(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7b8971558143a7a799fed6cf21d994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2928 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.09914879500865936,\n",
       " 'eval_accuracy': 0.9769427839453458,\n",
       " 'eval_recall': 0.9704505558806319,\n",
       " 'eval_precision': 0.9703086148895714,\n",
       " 'eval_f1': 0.970379580194544,\n",
       " 'eval_runtime': 360.5237,\n",
       " 'eval_samples_per_second': 48.721,\n",
       " 'eval_steps_per_second': 8.122,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate fine-tuned model\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a96606a75ec4be3b2599ca33ebb5533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2928 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.09680378437042236,\n",
       " 'test_accuracy': 0.9772856654901514,\n",
       " 'test_recall': 0.9723522527794032,\n",
       " 'test_precision': 0.9693743619658743,\n",
       " 'test_f1': 0.970861023880815,\n",
       " 'test_runtime': 418.5664,\n",
       " 'test_samples_per_second': 41.967,\n",
       " 'test_steps_per_second': 6.995}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict after fine-tuning\n",
    "trainer.predict(full_test_dataset).metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>training_loss</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.099149</td>\n",
       "      <td>0.976943</td>\n",
       "      <td>0.970309</td>\n",
       "      <td>0.970451</td>\n",
       "      <td>0.97038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  training_loss  validation_loss  accuracy  precision    recall  \\\n",
       "0    1.0            NaN         0.099149  0.976943   0.970309  0.970451   \n",
       "\n",
       "        f1  \n",
       "0  0.97038  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_training_history(wandb_run):\n",
    "  \"\"\"Extract key metrics from training and eval from wandb run data.\"\"\"\n",
    "\n",
    "  # Get training history from wandb\n",
    "  api = wandb.Api()\n",
    "  run = api.run(wandb_run)\n",
    "  history = run.history()\n",
    "\n",
    "  # Rename columns\n",
    "  train_column_dict = {'train/epoch': 'epoch', 'train/loss': 'training_loss'}\n",
    "  val_column_dict = {'train/epoch': 'epoch', 'eval/loss': 'validation_loss', 'eval/accuracy': 'accuracy',\n",
    "                'eval/precision': 'precision', 'eval/recall': 'recall', 'eval/f1': 'f1'}\n",
    "\n",
    "  # Train data\n",
    "  train_history = history[list(train_column_dict.keys())]\n",
    "  train_history.columns = [train_column_dict.get(x, x) for x in train_history.columns]\n",
    "  train_history = train_history.dropna()\n",
    "\n",
    "  # Val data\n",
    "  val_history = history[list(val_column_dict.keys())]\n",
    "  val_history.columns = [val_column_dict.get(x, x) for x in val_history.columns]\n",
    "  val_history = val_history.dropna()\n",
    "\n",
    "  return pd.merge(train_history, val_history, how=\"right\", on=\"epoch\")\n",
    "\n",
    "# Get dataframe for training history\n",
    "WANDB_RUN_ID = \"5jbw2h1y\" # Replace with your wandb run details, found in the training cell\n",
    "\n",
    "training_history = get_training_history(WANDB_ENTITY + \"/\" + WANDB_PROJECT + \"/\"  +WANDB_RUN_ID)\n",
    "training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71c02514cd44bf7af8b0b537670d8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2928 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.09680378437042236,\n",
       " 'test_accuracy': 0.9772856654901514,\n",
       " 'test_recall': 0.9723522527794032,\n",
       " 'test_precision': 0.9693743619658743,\n",
       " 'test_f1': 0.970861023880815,\n",
       " 'test_runtime': 422.9951,\n",
       " 'test_samples_per_second': 41.528,\n",
       " 'test_steps_per_second': 6.922}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load fine-tuned model\n",
    "saved_model = AutoModelForSequenceClassification.from_pretrained(MODEL_SAVE_PATH)\n",
    "\n",
    "# Load trainer after fine-tune\n",
    "saved_trainer = Trainer(\n",
    "    model=saved_model,\n",
    "    args=training_args,\n",
    "    train_dataset=full_train_dataset,\n",
    "    eval_dataset=full_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Predict after fine-tuning\n",
    "saved_trainer.predict(full_test_dataset).metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30377d154b5941b8824a217219eb9337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>‚ñÅ</td></tr><tr><td>eval/f1</td><td>‚ñÅ</td></tr><tr><td>eval/loss</td><td>‚ñÅ</td></tr><tr><td>eval/precision</td><td>‚ñÅ</td></tr><tr><td>eval/recall</td><td>‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ</td></tr><tr><td>test/accuracy</td><td>‚ñÅ‚ñà‚ñà</td></tr><tr><td>test/f1</td><td>‚ñÅ‚ñà‚ñà</td></tr><tr><td>test/loss</td><td>‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>test/precision</td><td>‚ñÅ‚ñà‚ñà</td></tr><tr><td>test/recall</td><td>‚ñÅ‚ñà‚ñà</td></tr><tr><td>test/runtime</td><td>‚ñÅ‚ñÜ‚ñà</td></tr><tr><td>test/samples_per_second</td><td>‚ñà‚ñÉ‚ñÅ</td></tr><tr><td>test/steps_per_second</td><td>‚ñà‚ñÉ‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ</td></tr><tr><td>train/learning_rate</td><td>‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.97694</td></tr><tr><td>eval/f1</td><td>0.97038</td></tr><tr><td>eval/loss</td><td>0.09915</td></tr><tr><td>eval/precision</td><td>0.97031</td></tr><tr><td>eval/recall</td><td>0.97045</td></tr><tr><td>eval/runtime</td><td>360.5237</td></tr><tr><td>eval/samples_per_second</td><td>48.721</td></tr><tr><td>eval/steps_per_second</td><td>8.122</td></tr><tr><td>test/accuracy</td><td>0.97729</td></tr><tr><td>test/f1</td><td>0.97086</td></tr><tr><td>test/loss</td><td>0.0968</td></tr><tr><td>test/precision</td><td>0.96937</td></tr><tr><td>test/recall</td><td>0.97235</td></tr><tr><td>test/runtime</td><td>422.9951</td></tr><tr><td>test/samples_per_second</td><td>41.528</td></tr><tr><td>test/steps_per_second</td><td>6.922</td></tr><tr><td>total_flos</td><td>3.697315483235328e+16</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>23421</td></tr><tr><td>train/grad_norm</td><td>15.90135</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1051</td></tr><tr><td>train_loss</td><td>0.05946</td></tr><tr><td>train_runtime</td><td>4951.4707</td></tr><tr><td>train_samples_per_second</td><td>28.38</td></tr><tr><td>train_steps_per_second</td><td>4.73</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bert</strong> at: <a href='https://wandb.ai/irshad-shariq-liverpool-john-moores-university/suicide-detection/runs/5jbw2h1y' target=\"_blank\">https://wandb.ai/irshad-shariq-liverpool-john-moores-university/suicide-detection/runs/5jbw2h1y</a><br/> View project at: <a href='https://wandb.ai/irshad-shariq-liverpool-john-moores-university/suicide-detection' target=\"_blank\">https://wandb.ai/irshad-shariq-liverpool-john-moores-university/suicide-detection</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240729_184035-5jbw2h1y\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Terminate wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Memory Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Delete variables and empty cache\n",
    "del trainer\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1701"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Python garbage collection\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456246784\n",
      "635437056\n"
     ]
    }
   ],
   "source": [
    "# Check memory allocation\n",
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      | 445553 KiB |   3148 MiB | 270726 GiB | 270725 GiB |\n",
      "|       from large pool | 445056 KiB |   3144 MiB | 270459 GiB | 270459 GiB |\n",
      "|       from small pool |    497 KiB |      4 MiB |    266 GiB |    266 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         | 445553 KiB |   3148 MiB | 270726 GiB | 270725 GiB |\n",
      "|       from large pool | 445056 KiB |   3144 MiB | 270459 GiB | 270459 GiB |\n",
      "|       from small pool |    497 KiB |      4 MiB |    266 GiB |    266 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      | 444319 KiB |   3142 MiB | 270515 GiB | 270515 GiB |\n",
      "|       from large pool | 443822 KiB |   3139 MiB | 270254 GiB | 270253 GiB |\n",
      "|       from small pool |    497 KiB |      4 MiB |    261 GiB |    261 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   | 620544 KiB |   3456 MiB |   5550 MiB |   4944 MiB |\n",
      "|       from large pool | 618496 KiB |   3450 MiB |   5540 MiB |   4936 MiB |\n",
      "|       from small pool |   2048 KiB |      6 MiB |     10 MiB |      8 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory | 174990 KiB | 390752 KiB | 188747 GiB | 188747 GiB |\n",
      "|       from large pool | 173440 KiB | 388480 KiB | 188420 GiB | 188420 GiB |\n",
      "|       from small pool |   1550 KiB |   3598 KiB |    327 GiB |    327 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     205    |    1020    |   48634 K  |   48634 K  |\n",
      "|       from large pool |      77    |     378    |   24397 K  |   24397 K  |\n",
      "|       from small pool |     128    |     718    |   24237 K  |   24237 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     205    |    1020    |   48634 K  |   48634 K  |\n",
      "|       from large pool |      77    |     378    |   24397 K  |   24397 K  |\n",
      "|       from small pool |     128    |     718    |   24237 K  |   24237 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      27    |     137    |     206    |     179    |\n",
      "|       from large pool |      26    |     134    |     201    |     175    |\n",
      "|       from small pool |       1    |       3    |       5    |       4    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      33    |     111    |   19658 K  |   19658 K  |\n",
      "|       from large pool |      30    |     104    |   14137 K  |   14137 K  |\n",
      "|       from small pool |       3    |      18    |    5521 K  |    5521 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check memory summary\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 30 02:27:14 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 556.12                 Driver Version: 556.12         CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   47C    P5             17W /   85W |     985MiB /   8192MiB |     30%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     15280    C+G   D:\\Microsoft VS Code\\Code.exe               N/A      |\n",
      "|    0   N/A  N/A     25840      C   D:\\python\\python.exe                        N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check GPU allocation and acprocesses\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
