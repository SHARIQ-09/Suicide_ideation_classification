{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\python\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ex Wife Threatening SuicideRecently I left my ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Am I weird I don't get affected by compliments...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finally 2020 is almost over... So I can never ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It ends tonight.I can’t do it anymore. \\nI quit.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Ex Wife Threatening SuicideRecently I left my ...      1\n",
       "1  Am I weird I don't get affected by compliments...      0\n",
       "2  Finally 2020 is almost over... So I can never ...      0\n",
       "3          i need helpjust help me im crying so hard      1\n",
       "4   It ends tonight.I can’t do it anymore. \\nI quit.      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('suicide_detection_final_cleaned.csv', header=0, names=['text', 'label', 'cleaned_text'])\n",
    "df['label'] = df['label'].map({'suicide': 1, 'non-suicide': 0})\n",
    "df.drop(columns=['cleaned_text'], inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 6\n",
    "LEARNING_RATE = 1e-5\n",
    "SEED = 90\n",
    "\n",
    "MODEL_SAVE_PATH = \"Models/RoBERTa\"\n",
    "MODEL_CHECKPOINT_PATH = \"Models/RoBERTa_checkpoint\"\n",
    "MODEL_LOGGING_PATH = \"Models/RoBERT_checkpoint/logs\"\n",
    "\n",
    "#WANDB_ENTITY = \"irshad-shariq-liverpool-john-moores-university\"\n",
    "#WANDB_PROJECT = \"suicide-detection\"\n",
    "#WANDB_RUN = \"bert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train, validation and test sets\n",
    "train, temp = train_test_split(df,\n",
    "                               random_state=SEED,\n",
    "                               test_size=0.2,\n",
    "                               stratify=df['label'])\n",
    "\n",
    "val, test = train_test_split(temp,\n",
    "                             random_state=SEED,\n",
    "                             test_size=0.5,\n",
    "                             stratify=temp['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load RoBERTa tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_conversion(train, test, val):\n",
    "  \"\"\"Converts pandas dataframe to Dataset.\"\"\"\n",
    "\n",
    "  train.reset_index(drop=True, inplace=True)\n",
    "  test.reset_index(drop=True, inplace=True)\n",
    "  val.reset_index(drop=True, inplace=True)\n",
    "\n",
    "  train_dataset = Dataset.from_pandas(train)\n",
    "  test_dataset = Dataset.from_pandas(test)\n",
    "  val_dataset = Dataset.from_pandas(val)\n",
    "\n",
    "  return DatasetDict({\"train\": train_dataset,\n",
    "                      \"test\": test_dataset,\n",
    "                      \"val\": val_dataset})\n",
    "\n",
    "raw_datasets = dataset_conversion(train, test, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0006e86ca3f4d1d9ed602faf7280dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/140523 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571ec7fa2863467bba87f4ae421342b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17566 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4351a420219f4572b4a2543452f6db8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17565 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(dataset):\n",
    "    return tokenizer(dataset[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenise datasets\n",
    "#SAMPLE_SIZE = 20\n",
    "#small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=SEED).select(range(SAMPLE_SIZE))\n",
    "#small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=SEED).select(range(SAMPLE_SIZE))\n",
    "#small_val_dataset = tokenized_datasets[\"val\"].shuffle(seed=SEED).select(range(SAMPLE_SIZE))\n",
    "\n",
    "full_train_dataset = tokenized_datasets[\"train\"]\n",
    "full_test_dataset = tokenized_datasets[\"test\"]\n",
    "full_val_dataset = tokenized_datasets[\"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RoBERTa -base pretrained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\", num_labels=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom metrics for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load \n",
    "def compute_metrics(eval_pred):\n",
    "    metric_acc = load(\"accuracy\")\n",
    "    metric_rec = load(\"recall\")\n",
    "    metric_pre = load(\"precision\")\n",
    "    metric_f1 = load(\"f1\")\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    accuracy = metric_acc.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    recall = metric_rec.compute(predictions=predictions, references=labels, average='macro',zero_division=0)[\"recall\"]\n",
    "    precision = metric_pre.compute(predictions=predictions, references=labels, average='macro',zero_division=0)[\"precision\"]\n",
    "    f1 = metric_f1.compute(predictions=predictions, references=labels, average='macro')[\"f1\"]\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"f1\": f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model and training parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_CHECKPOINT_PATH,\n",
    "    overwrite_output_dir = True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    seed=SEED,\n",
    "    logging_dir=MODEL_LOGGING_PATH,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1500,\n",
    "    report_to=[\"none\"]\n",
    ")\n",
    "# \n",
    "    #run_name=WANDB_RUN,\n",
    "   #report_to = 'wandb',\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=full_train_dataset,\n",
    "    eval_dataset=full_val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-Trained RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b80061b20f47fea12430fc0f48a23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2928 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 3.734851837158203,\n",
       " 'test_accuracy': 0.09985198679266766,\n",
       " 'test_recall': 0.025748948353415575,\n",
       " 'test_precision': 0.12465439114451837,\n",
       " 'test_f1': 0.04259237648688736,\n",
       " 'test_runtime': 791.5275,\n",
       " 'test_samples_per_second': 22.193,\n",
       " 'test_steps_per_second': 3.699}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict before fine-tuning\n",
    "trainer.predict(full_test_dataset).metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuned RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640b7e67c66c452dbb7ae66ffb5e7b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4665, 'grad_norm': 16.310157775878906, 'learning_rate': 9.7865163741941e-06, 'epoch': 0.02}\n",
      "{'loss': 0.2787, 'grad_norm': 26.21689796447754, 'learning_rate': 9.573032748388199e-06, 'epoch': 0.04}\n",
      "{'loss': 0.1348, 'grad_norm': 2.0396459102630615, 'learning_rate': 9.3595491225823e-06, 'epoch': 0.06}\n",
      "{'loss': 0.0832, 'grad_norm': 0.0051724230870604515, 'learning_rate': 9.146065496776399e-06, 'epoch': 0.09}\n",
      "{'loss': 0.0995, 'grad_norm': 0.4950341582298279, 'learning_rate': 8.932581870970498e-06, 'epoch': 0.11}\n",
      "{'loss': 0.0944, 'grad_norm': 0.023596251383423805, 'learning_rate': 8.719098245164597e-06, 'epoch': 0.13}\n",
      "{'loss': 0.0861, 'grad_norm': 0.7253497838973999, 'learning_rate': 8.505614619358696e-06, 'epoch': 0.15}\n",
      "{'loss': 0.0639, 'grad_norm': 0.005385054741054773, 'learning_rate': 8.292130993552795e-06, 'epoch': 0.17}\n",
      "{'loss': 0.0797, 'grad_norm': 0.3268435299396515, 'learning_rate': 8.078647367746895e-06, 'epoch': 0.19}\n",
      "{'loss': 0.0857, 'grad_norm': 0.01800481788814068, 'learning_rate': 7.865163741940994e-06, 'epoch': 0.21}\n",
      "{'loss': 0.0759, 'grad_norm': 1.1279728412628174, 'learning_rate': 7.651680116135094e-06, 'epoch': 0.23}\n",
      "{'loss': 0.0431, 'grad_norm': 0.010708329267799854, 'learning_rate': 7.4381964903291925e-06, 'epoch': 0.26}\n",
      "{'loss': 0.0722, 'grad_norm': 0.07724397629499435, 'learning_rate': 7.224712864523291e-06, 'epoch': 0.28}\n",
      "{'loss': 0.0421, 'grad_norm': 0.003414939856156707, 'learning_rate': 7.011229238717391e-06, 'epoch': 0.3}\n",
      "{'loss': 0.0734, 'grad_norm': 0.004072582349181175, 'learning_rate': 6.7977456129114905e-06, 'epoch': 0.32}\n",
      "{'loss': 0.0602, 'grad_norm': 0.0035551569890230894, 'learning_rate': 6.584261987105589e-06, 'epoch': 0.34}\n",
      "{'loss': 0.059, 'grad_norm': 0.045824285596609116, 'learning_rate': 6.3707783612996885e-06, 'epoch': 0.36}\n",
      "{'loss': 0.0595, 'grad_norm': 0.0036438077222555876, 'learning_rate': 6.157294735493788e-06, 'epoch': 0.38}\n",
      "{'loss': 0.0495, 'grad_norm': 0.008743777871131897, 'learning_rate': 5.943811109687887e-06, 'epoch': 0.41}\n",
      "{'loss': 0.053, 'grad_norm': 37.51003646850586, 'learning_rate': 5.7303274838819865e-06, 'epoch': 0.43}\n",
      "{'loss': 0.0515, 'grad_norm': 0.006721359211951494, 'learning_rate': 5.516843858076086e-06, 'epoch': 0.45}\n",
      "{'loss': 0.0662, 'grad_norm': 1.4798390865325928, 'learning_rate': 5.3033602322701845e-06, 'epoch': 0.47}\n",
      "{'loss': 0.0581, 'grad_norm': 0.03646569699048996, 'learning_rate': 5.089876606464284e-06, 'epoch': 0.49}\n",
      "{'loss': 0.0386, 'grad_norm': 0.0023171466309577227, 'learning_rate': 4.8763929806583834e-06, 'epoch': 0.51}\n",
      "{'loss': 0.0515, 'grad_norm': 0.005401731934398413, 'learning_rate': 4.662909354852483e-06, 'epoch': 0.53}\n",
      "{'loss': 0.0473, 'grad_norm': 0.0025137714110314846, 'learning_rate': 4.449425729046582e-06, 'epoch': 0.56}\n",
      "{'loss': 0.057, 'grad_norm': 0.0035329782404005527, 'learning_rate': 4.235942103240681e-06, 'epoch': 0.58}\n",
      "{'loss': 0.0619, 'grad_norm': 0.010108714923262596, 'learning_rate': 4.022458477434781e-06, 'epoch': 0.6}\n",
      "{'loss': 0.0441, 'grad_norm': 0.005381495226174593, 'learning_rate': 3.8089748516288807e-06, 'epoch': 0.62}\n",
      "{'loss': 0.0494, 'grad_norm': 0.1864854246377945, 'learning_rate': 3.5954912258229797e-06, 'epoch': 0.64}\n",
      "{'loss': 0.0421, 'grad_norm': 0.05627387389540672, 'learning_rate': 3.3820076000170787e-06, 'epoch': 0.66}\n",
      "{'loss': 0.041, 'grad_norm': 0.022295013070106506, 'learning_rate': 3.1685239742111786e-06, 'epoch': 0.68}\n",
      "{'loss': 0.0515, 'grad_norm': 0.004893458914011717, 'learning_rate': 2.9550403484052776e-06, 'epoch': 0.7}\n",
      "{'loss': 0.0468, 'grad_norm': 0.04276253655552864, 'learning_rate': 2.7415567225993767e-06, 'epoch': 0.73}\n",
      "{'loss': 0.0346, 'grad_norm': 0.01016418356448412, 'learning_rate': 2.5280730967934765e-06, 'epoch': 0.75}\n",
      "{'loss': 0.0405, 'grad_norm': 0.0030030652415007353, 'learning_rate': 2.3145894709875756e-06, 'epoch': 0.77}\n",
      "{'loss': 0.0348, 'grad_norm': 0.0015804560389369726, 'learning_rate': 2.101105845181675e-06, 'epoch': 0.79}\n",
      "{'loss': 0.0491, 'grad_norm': 0.0058799064718186855, 'learning_rate': 1.887622219375774e-06, 'epoch': 0.81}\n",
      "{'loss': 0.0398, 'grad_norm': 0.0005999826826155186, 'learning_rate': 1.6741385935698735e-06, 'epoch': 0.83}\n",
      "{'loss': 0.0397, 'grad_norm': 0.02066417783498764, 'learning_rate': 1.4606549677639725e-06, 'epoch': 0.85}\n",
      "{'loss': 0.0462, 'grad_norm': 0.03224189206957817, 'learning_rate': 1.247171341958072e-06, 'epoch': 0.88}\n",
      "{'loss': 0.0346, 'grad_norm': 0.0015036719851195812, 'learning_rate': 1.0336877161521712e-06, 'epoch': 0.9}\n",
      "{'loss': 0.059, 'grad_norm': 0.007199747022241354, 'learning_rate': 8.202040903462705e-07, 'epoch': 0.92}\n",
      "{'loss': 0.0425, 'grad_norm': 0.0009073942201212049, 'learning_rate': 6.067204645403698e-07, 'epoch': 0.94}\n",
      "{'loss': 0.0448, 'grad_norm': 0.02375122532248497, 'learning_rate': 3.9323683873446906e-07, 'epoch': 0.96}\n",
      "{'loss': 0.0461, 'grad_norm': 0.0392477884888649, 'learning_rate': 1.797532129285684e-07, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5153ead2802423eafdbd4c7ab68259d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2928 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03629041463136673, 'eval_accuracy': 0.9926558497011102, 'eval_recall': 0.9917323966951974, 'eval_precision': 0.9928161785353395, 'eval_f1': 0.9922679992598877, 'eval_runtime': 196.4235, 'eval_samples_per_second': 89.424, 'eval_steps_per_second': 14.907, 'epoch': 1.0}\n",
      "{'train_runtime': 7664.9822, 'train_samples_per_second': 18.333, 'train_steps_per_second': 3.056, 'train_loss': 0.07083109718877506, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f9b079902d42ba914bc155f61a51bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0662, 'grad_norm': 1.4798390865325928, 'learning_rate': 5.3033602322701845e-06, 'epoch': 0.47}\n",
      "{'loss': 0.0581, 'grad_norm': 0.03646569699048996, 'learning_rate': 5.089876606464284e-06, 'epoch': 0.49}\n",
      "{'loss': 0.0386, 'grad_norm': 0.0023171466309577227, 'learning_rate': 4.8763929806583834e-06, 'epoch': 0.51}\n",
      "{'loss': 0.0515, 'grad_norm': 0.005401731934398413, 'learning_rate': 4.662909354852483e-06, 'epoch': 0.53}\n",
      "{'loss': 0.0473, 'grad_norm': 0.0025137714110314846, 'learning_rate': 4.449425729046582e-06, 'epoch': 0.56}\n",
      "{'loss': 0.057, 'grad_norm': 0.0035329782404005527, 'learning_rate': 4.235942103240681e-06, 'epoch': 0.58}\n",
      "{'loss': 0.0619, 'grad_norm': 0.010108714923262596, 'learning_rate': 4.022458477434781e-06, 'epoch': 0.6}\n",
      "{'loss': 0.0441, 'grad_norm': 0.005381495226174593, 'learning_rate': 3.8089748516288807e-06, 'epoch': 0.62}\n",
      "{'loss': 0.0494, 'grad_norm': 0.1864854246377945, 'learning_rate': 3.5954912258229797e-06, 'epoch': 0.64}\n",
      "{'loss': 0.0421, 'grad_norm': 0.05627387389540672, 'learning_rate': 3.3820076000170787e-06, 'epoch': 0.66}\n",
      "{'loss': 0.041, 'grad_norm': 0.022295013070106506, 'learning_rate': 3.1685239742111786e-06, 'epoch': 0.68}\n",
      "{'loss': 0.0515, 'grad_norm': 0.004893458914011717, 'learning_rate': 2.9550403484052776e-06, 'epoch': 0.7}\n",
      "{'loss': 0.0468, 'grad_norm': 0.04276253655552864, 'learning_rate': 2.7415567225993767e-06, 'epoch': 0.73}\n",
      "{'loss': 0.0346, 'grad_norm': 0.01016418356448412, 'learning_rate': 2.5280730967934765e-06, 'epoch': 0.75}\n",
      "{'loss': 0.0405, 'grad_norm': 0.0030030652415007353, 'learning_rate': 2.3145894709875756e-06, 'epoch': 0.77}\n",
      "{'loss': 0.0348, 'grad_norm': 0.0015804560389369726, 'learning_rate': 2.101105845181675e-06, 'epoch': 0.79}\n",
      "{'loss': 0.0491, 'grad_norm': 0.0058799064718186855, 'learning_rate': 1.887622219375774e-06, 'epoch': 0.81}\n",
      "{'loss': 0.0398, 'grad_norm': 0.0005999826826155186, 'learning_rate': 1.6741385935698735e-06, 'epoch': 0.83}\n",
      "{'loss': 0.0397, 'grad_norm': 0.02066417783498764, 'learning_rate': 1.4606549677639725e-06, 'epoch': 0.85}\n",
      "{'loss': 0.0462, 'grad_norm': 0.03224189206957817, 'learning_rate': 1.247171341958072e-06, 'epoch': 0.88}\n",
      "{'loss': 0.0346, 'grad_norm': 0.0015036719851195812, 'learning_rate': 1.0336877161521712e-06, 'epoch': 0.9}\n",
      "{'loss': 0.059, 'grad_norm': 0.007199747022241354, 'learning_rate': 8.202040903462705e-07, 'epoch': 0.92}\n",
      "{'loss': 0.0425, 'grad_norm': 0.0009073942201212049, 'learning_rate': 6.067204645403698e-07, 'epoch': 0.94}\n",
      "{'loss': 0.0448, 'grad_norm': 0.02375122532248497, 'learning_rate': 3.9323683873446906e-07, 'epoch': 0.96}\n",
      "{'loss': 0.0461, 'grad_norm': 0.0392477884888649, 'learning_rate': 1.797532129285684e-07, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5954b3b55d864e829a60c03be86eed1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2928 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03629041463136673, 'eval_accuracy': 0.9926558497011102, 'eval_recall': 0.9917323966951974, 'eval_precision': 0.9928161785353395, 'eval_f1': 0.9922679992598877, 'eval_runtime': 197.996, 'eval_samples_per_second': 88.714, 'eval_steps_per_second': 14.788, 'epoch': 1.0}\n",
      "{'train_runtime': 2809.7963, 'train_samples_per_second': 50.012, 'train_steps_per_second': 8.335, 'train_loss': 0.025746483841681836, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=23421, training_loss=0.025746483841681836, metrics={'train_runtime': 2809.7963, 'train_samples_per_second': 50.012, 'train_steps_per_second': 8.335, 'total_flos': 1.861637609652941e+16, 'train_loss': 0.025746483841681836, 'epoch': 1.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To observe training progress live\n",
    "#%%wandb \n",
    "\n",
    "# Fine-tune model\n",
    "trainer.train()\n",
    "\n",
    "# Resume fine-tuning from checkpoint\n",
    "trainer.train(MODEL_CHECKPOINT_PATH + \"/\" + \"checkpoint-10500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fine-tuned model\n",
    "trainer.save_model(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f6aa59285c401e9994301bb51fa50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2928 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.03629041463136673,\n",
       " 'eval_accuracy': 0.9926558497011102,\n",
       " 'eval_recall': 0.9917323966951974,\n",
       " 'eval_precision': 0.9928161785353395,\n",
       " 'eval_f1': 0.9922679992598877,\n",
       " 'eval_runtime': 217.0816,\n",
       " 'eval_samples_per_second': 80.914,\n",
       " 'eval_steps_per_second': 13.488,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate fine-tuned model\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13ff62a6e6247f89e4199346c98e5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2928 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.034782037138938904,\n",
       " 'test_accuracy': 0.9931116930433792,\n",
       " 'test_recall': 0.9922380937059818,\n",
       " 'test_precision': 0.9932695982054867,\n",
       " 'test_f1': 0.9927481543095249,\n",
       " 'test_runtime': 209.3322,\n",
       " 'test_samples_per_second': 83.914,\n",
       " 'test_steps_per_second': 13.987}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict after fine-tuning\n",
    "trainer.predict(full_test_dataset).metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba38ee0f16504c5ca3d15be20bf92ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2928 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.034782037138938904,\n",
       " 'test_accuracy': 0.9931116930433792,\n",
       " 'test_recall': 0.9922380937059818,\n",
       " 'test_precision': 0.9932695982054867,\n",
       " 'test_f1': 0.9927481543095249,\n",
       " 'test_runtime': 210.6437,\n",
       " 'test_samples_per_second': 83.392,\n",
       " 'test_steps_per_second': 13.9}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load fine-tuned model\n",
    "saved_model = AutoModelForSequenceClassification.from_pretrained(MODEL_SAVE_PATH)\n",
    "\n",
    "# Load trainer after fine-tune\n",
    "saved_trainer = Trainer(\n",
    "    model=saved_model,\n",
    "    args=training_args,\n",
    "    train_dataset=full_train_dataset,\n",
    "    eval_dataset=full_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Predict after fine-tuning\n",
    "saved_trainer.predict(full_test_dataset).metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
